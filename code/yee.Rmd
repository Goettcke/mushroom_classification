---
title: "Applied Machine Learning, Assignment 3"
author: "Jonatan Møller Gøttcke"
date: "2018 M05 3"
output: html_document
---
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # This is for general case setting working directory.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Setting working
```{r working, include = TRUE} 
library(rstudioapi) 
library(e1071)
library(caret)
library(randomForest)
library(ggplot2)
``` 

## Loading data
```{r load_data, include=TRUE}
mushroom_data <- read.csv("../data/agaricus-lepiota.data", header = F,stringsAsFactors = TRUE)
colnames(mushroom_data)[1] = "Class" #Renaming so we know this is the Class
target <- mushroom_data[,1] #Making a Class array if anything needs it
target[1:10] # Contains information the labels of the different mushrooms.
```

##Summary 
```{r summary, include=TRUE}
summary(mushroom_data)

``` 
Here we can see that column 17 only includes attributes with the value p, so this is a bit useless, and the randomForest algorithm "rf", as used in crossvalidation can handle this, so these are omitted. This attribute describes the veil-type which is a either partial or universal. In mushrooms such as the *amanita caesarea* the veil is universal when the mushroom is young, and is broken as the mushroom grows. Ths is very common for adult mushrooms, and some like the famous *fly amanita* or as known by mycologist *amanita muscaria* has a very visible partial veil, which is the white dots on the red cap, that makes it so characteristic. It would be outside of the scope of this task to give more insight into the variables, but the reader can find more information here [link]https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.names.  


```{r dropping_values, include=TRUE}
indices_without_17 <- c(1:16,18:ncol(mushroom_data))
 # The 17'th column only contains 1 attribute value, so it is omitted, because is useless information. 
mushroom_data <- mushroom_data[,indices_without_17]
mushroom_data_nolabel <- mushroom_data[,2:ncol(mushroom_data)]
summary(mushroom_data)
``` 
Now the value is dropped, and we can continue to do some classification. 


## Naive Bayes Classifier
```{r NaïveBayes, include=TRUE}
mushroom_data$Class[1:20]
model <- naiveBayes(Class ~ .,data = mushroom_data)
pred <- predict(model,mushroom_data)
correct_predictions <- pred == target
t_correct_predictions <- as.data.frame(correct_predictions)
length(which(correct_predictions == TRUE %in% t_correct_predictions)) #Counting the number of values that are classified correctly. 
pred[1:10]

nb_confucius_matrix <- confusionMatrix(
                                      factor(pred),
                                      factor(target))
nb_confucius_matrix # To output the result in comparison with the target. 
```

As can be seen here the confusion matrix, there are a ot of true positives, when predicting the edible class. This is good news! Because for this dataset it means, that if our classifier predicts we can eat the mushroom, then we can with a very high probability eat the mushroom. 

##Random Forest Classifier 
```{r random_forest, include = TRUE}
  rf_model <- randomForest(Class ~., data = mushroom_data, important=True, proximity=TRUE)
  rf_model$predicted
  rf_confucius_matrix <- confusionMatrix(factor(rf_model$predicted),factor(target))
  rf_confucius_matrix
``` 


In the randomForest we classify everything perfectly, which of course shows a flaw in our design, and something decision trees are really good at - **overfitting** . First we try to split the dataset into two parts and train on the first 90% of the data, and then evaluate on the final ten.  

##Splitting
```{r splitting, include=TRUE}
  split_index <- ceiling(nrow(mushroom_data) * 0.8)
  train_data <- mushroom_data[1:split_index,]
  test_data <- mushroom_data[(split_index +1):nrow(mushroom_data),]
  
  rf_model <- randomForest(Class ~., data = train_data, important=True, proximity=TRUE)
  rf_model$pred <- predict(rf_model, test_data[,2:ncol(test_data)]) # here i just for absolute certainty remove the class column . 
  rf_model$pred
  rf_model$confusion # Only shows the confusion matrix generated when training the model. Here it seems, that the model has simply learned all the data by heart. 
  
  rf_confucius_matrix <- confusionMatrix(factor(rf_model$pred),factor(target[(split_index+1):length(target)]))
  rf_confucius_matrix
  
```
Here we can see, that with the split at 90%, the model still performs impeccable. If we split at 60% and test on 40 percent of the data, then we still obtain a decent classifier however, we have a fairly low sensitivity at 89.91% meaning if we take tp/(tp+fp), meaning out of the total amount of times our classifier recommends us to eat the mushroom, we don't get poisoned in 89% of the time. Now if we randomly pick 10 mushrooms, and use our classifier to predict if we should eat them, and let's say there's an even probability for the mushrooms being poisonous and edible, then we have a 34% chance of not being poisoned, so this is not the greatest classifier. 


##cross validation

```{r cv, include=TRUE}
#First we do crossValidation on the Naïve Bayes
train_control <- trainControl(method="cv", number = 10)
rf_model <- train(Class ~ V2, data = mushroom_data, method = "rf", trControl=train_control)
rf_model$confusion
rf_model$finalModel

train_control <- trainControl(method='cv', number = 1)
nb_model<- train(Class ~., data =mushroom_data, method = "nb",trControl=train_control)

```

```{r cars}
summary(cars)
```


```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
